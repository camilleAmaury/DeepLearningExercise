{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network\n",
    "\n",
    "This notebook was created by Camille-Amaury JUGE, in order to better understand ANN principles and how they work.\n",
    "\n",
    "(it follows the exercices proposed by Hadelin de Ponteves on Udemy : https://www.udemy.com/course/le-deep-learning-de-a-a-z/)\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# scikit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "# keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset deals with banking customer's account, with several information on each individuals. The major problem to explore is that some of the customers are leaving the bank for some reasons that we don't know. \n",
    "\n",
    "Our aim is then to find profile(s) which match the leaving conditions and find a solution to keep the customers matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we see that we only have categorical or continuous data. This will be easy do deal with by using sklearn encoders.\n",
    "Nextly, we want to check the different distribution of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2887.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2501.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerId</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>15690941.0</td>\n",
       "      <td>71936.0</td>\n",
       "      <td>15565701.0</td>\n",
       "      <td>15628528.0</td>\n",
       "      <td>15690738.0</td>\n",
       "      <td>15753234.0</td>\n",
       "      <td>15815690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditScore</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>651.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>718.0</td>\n",
       "      <td>850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balance</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>76486.0</td>\n",
       "      <td>62397.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97199.0</td>\n",
       "      <td>127644.0</td>\n",
       "      <td>250898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumOfProducts</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasCrCard</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsActiveMember</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>100090.0</td>\n",
       "      <td>57510.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>51002.0</td>\n",
       "      <td>100194.0</td>\n",
       "      <td>149388.0</td>\n",
       "      <td>199992.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exited</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count        mean      std         min         25%  \\\n",
       "RowNumber        10000.0      5000.0   2887.0         1.0      2501.0   \n",
       "CustomerId       10000.0  15690941.0  71936.0  15565701.0  15628528.0   \n",
       "CreditScore      10000.0       651.0     97.0       350.0       584.0   \n",
       "Age              10000.0        39.0     10.0        18.0        32.0   \n",
       "Tenure           10000.0         5.0      3.0         0.0         3.0   \n",
       "Balance          10000.0     76486.0  62397.0         0.0         0.0   \n",
       "NumOfProducts    10000.0         2.0      1.0         1.0         1.0   \n",
       "HasCrCard        10000.0         1.0      0.0         0.0         0.0   \n",
       "IsActiveMember   10000.0         1.0      0.0         0.0         0.0   \n",
       "EstimatedSalary  10000.0    100090.0  57510.0        12.0     51002.0   \n",
       "Exited           10000.0         0.0      0.0         0.0         0.0   \n",
       "\n",
       "                        50%         75%         max  \n",
       "RowNumber            5000.0      7500.0     10000.0  \n",
       "CustomerId       15690738.0  15753234.0  15815690.0  \n",
       "CreditScore           652.0       718.0       850.0  \n",
       "Age                    37.0        44.0        92.0  \n",
       "Tenure                  5.0         7.0        10.0  \n",
       "Balance             97199.0    127644.0    250898.0  \n",
       "NumOfProducts           1.0         2.0         4.0  \n",
       "HasCrCard               1.0         1.0         1.0  \n",
       "IsActiveMember          1.0         1.0         1.0  \n",
       "EstimatedSalary    100194.0    149388.0    199992.0  \n",
       "Exited                  0.0         0.0         1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can clearly see that :\n",
    "* The percentage of people who leaved is lower than 25% (which is quite comforting).\n",
    "* The distribution over the credit score is balanced (mean ~ median).\n",
    "* The distribution over the Balance is going lower meaning that there are more outliers with little of money (mean < median).\n",
    "* The distribution over the estimated Salary seems quite balanced too.\n",
    "* The overall age is also balanced between younger and older people (which may earns more) around 37 years old for the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>5014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spain</th>\n",
       "      <td>2477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Geography\n",
       "France        5014\n",
       "Germany       2509\n",
       "Spain         2477"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df[\"Geography\"].value_counts().transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see that the Bank has collected the double of information in France than in Germany and Spain. Then the network could perform better on the France's customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>5457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>4543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Gender\n",
       "Male      5457\n",
       "Female    4543"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df[\"Gender\"].value_counts().transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the gender distribution is quite balanced, there is just less women."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "\n",
    "We will now convert categorical variables for the network, and also deal with useless variable such as id, name ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df.loc[:,df.columns[3:]]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder_converting(x):\n",
    "    label_encoder = LabelEncoder()\n",
    "    return label_encoder.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France       0   42       2       0.00              1   \n",
       "1          608     Spain       0   41       1   83807.86              1   \n",
       "2          502    France       0   42       8  159660.80              3   \n",
       "3          699    France       0   39       1       0.00              2   \n",
       "4          850     Spain       0   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Gender\"] = label_encoder_converting(df_train[\"Gender\"])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder_converting(x):\n",
    "    one_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    return one_hot_encoder.fit_transform(x).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  1.0  0.0  0.0\n",
       "1  0.0  0.0  1.0\n",
       "2  1.0  0.0  0.0\n",
       "3  1.0  0.0  0.0\n",
       "4  0.0  0.0  1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_df = pd.DataFrame(one_hot_encoder_converting(df_train[[\"Geography\"]]))\n",
    "geo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only have three values (following binary theory) and we have three columns, we will delete one which is useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619       0   42       2       0.00              1          1   \n",
       "1          608       0   41       1   83807.86              1          0   \n",
       "2          502       0   42       8  159660.80              3          1   \n",
       "3          699       0   39       1       0.00              2          0   \n",
       "4          850       0   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited    1    2  \n",
       "0               1        101348.88       1  0.0  0.0  \n",
       "1               1        112542.58       0  0.0  1.0  \n",
       "2               0        113931.57       1  0.0  0.0  \n",
       "3               0         93826.63       0  0.0  0.0  \n",
       "4               1         79084.10       0  0.0  1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_df = geo_df.drop(labels=[0], axis=1)\n",
    "df_train = df_train.drop(labels=[\"Geography\"], axis=1)\n",
    "df_train = pd.concat([df_train, geo_df], axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train[\"Exited\"]\n",
    "X = df_train.drop(labels=[\"Exited\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now scale every values to help the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.326221</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-1.041760</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.440036</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>-1.387538</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.536794</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>1.032908</td>\n",
       "      <td>1.333053</td>\n",
       "      <td>2.527057</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>0.240687</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501521</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-1.387538</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.108918</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.573809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.063884</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.388871</td>\n",
       "      <td>-1.041760</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-0.365276</td>\n",
       "      <td>-0.578736</td>\n",
       "      <td>1.742740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.326221 -1.095988  0.293517 -1.041760 -1.225848 -0.911583  0.646092   \n",
       "1 -0.440036 -1.095988  0.198164 -1.387538  0.117350 -0.911583 -1.547768   \n",
       "2 -1.536794 -1.095988  0.293517  1.032908  1.333053  2.527057  0.646092   \n",
       "3  0.501521 -1.095988  0.007457 -1.387538 -1.225848  0.807737 -1.547768   \n",
       "4  2.063884 -1.095988  0.388871 -1.041760  0.785728 -0.911583  0.646092   \n",
       "\n",
       "         7         8         9         10  \n",
       "0  0.970243  0.021886 -0.578736 -0.573809  \n",
       "1  0.970243  0.216534 -0.578736  1.742740  \n",
       "2 -1.030670  0.240687 -0.578736 -0.573809  \n",
       "3 -1.030670 -0.108918 -0.578736 -0.573809  \n",
       "4  0.970243 -0.365276 -0.578736  1.742740  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X = pd.DataFrame(std_scaler.fit_transform(X))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(labels, length):\n",
    "    x_labels = []\n",
    "    for i in range(length):\n",
    "        x_labels.append(\"Predicted {}\".format(labels[i]))\n",
    "    y_labels = []\n",
    "    for i in range(length):\n",
    "        y_labels.append(\"Is {}\".format(labels[i]))\n",
    "    return (x_labels, y_labels)\n",
    "\n",
    "def heatmap_numbers(m, labels, title):\n",
    "    lenght = len(labels)\n",
    "    \n",
    "    # Creating plot base config\n",
    "    fig, ax = plt.subplots(figsize=(16,10))\n",
    "    im = ax.imshow(m, cmap=\"copper\")\n",
    "    \n",
    "    # Creating labels\n",
    "    (x_axis_labels, y_axis_labels) = create_labels(labels, lenght)\n",
    "\n",
    "    # Positionning Labels on axis\n",
    "    ax.set_xticks(np.arange(lenght))\n",
    "    ax.set_xticklabels(x_axis_labels)\n",
    "    ax.set_yticks(np.arange(lenght))\n",
    "    ax.set_yticklabels(y_axis_labels)\n",
    "    ax.grid(False)\n",
    "\n",
    "    # Rotate labels on x axis\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # Put values in each case\n",
    "    for i in range(lenght):\n",
    "        for j in range(lenght):\n",
    "            text = ax.text(j, i, m[i, j], ha=\"center\", va=\"center\", color=\"red\", fontsize=\"large\")\n",
    "\n",
    "    ax.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 79\n",
      "Trainable params: 79\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model creation\n",
    "clf_model_1 = Sequential()\n",
    "# Input layer and first Hidden Layer\n",
    "clf_model_1.add(Dense(units=6, activation=\"relu\", \n",
    "                      kernel_initializer=\"uniform\", \n",
    "                      input_dim=X_train.shape[1]))\n",
    "# OutputLayer\n",
    "clf_model_1.add(Dense(units=1, activation=\"sigmoid\", \n",
    "                      kernel_initializer=\"uniform\"))\n",
    "clf_model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/100\n",
      "6750/6750 [==============================] - 0s 55us/step - loss: 0.6148 - accuracy: 0.7923 - val_loss: 0.5089 - val_accuracy: 0.7987\n",
      "Epoch 2/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4572 - accuracy: 0.7945 - val_loss: 0.4351 - val_accuracy: 0.7987\n",
      "Epoch 3/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4310 - accuracy: 0.7945 - val_loss: 0.4293 - val_accuracy: 0.7987\n",
      "Epoch 4/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.4276 - accuracy: 0.7945 - val_loss: 0.4269 - val_accuracy: 0.7987\n",
      "Epoch 5/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4258 - accuracy: 0.7945 - val_loss: 0.4253 - val_accuracy: 0.7987\n",
      "Epoch 6/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4244 - accuracy: 0.7945 - val_loss: 0.4249 - val_accuracy: 0.7987\n",
      "Epoch 7/100\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.4229 - accuracy: 0.7945 - val_loss: 0.4240 - val_accuracy: 0.7987\n",
      "Epoch 8/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4216 - accuracy: 0.7945 - val_loss: 0.4222 - val_accuracy: 0.7987\n",
      "Epoch 9/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.4202 - accuracy: 0.7945 - val_loss: 0.4209 - val_accuracy: 0.7987\n",
      "Epoch 10/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.4190 - accuracy: 0.7948 - val_loss: 0.4203 - val_accuracy: 0.8160\n",
      "Epoch 11/100\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.4178 - accuracy: 0.8182 - val_loss: 0.4191 - val_accuracy: 0.8240\n",
      "Epoch 12/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4168 - accuracy: 0.8213 - val_loss: 0.4178 - val_accuracy: 0.8227\n",
      "Epoch 13/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4156 - accuracy: 0.8231 - val_loss: 0.4171 - val_accuracy: 0.8227\n",
      "Epoch 14/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4147 - accuracy: 0.8256 - val_loss: 0.4163 - val_accuracy: 0.8213\n",
      "Epoch 15/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4138 - accuracy: 0.8265 - val_loss: 0.4156 - val_accuracy: 0.8280\n",
      "Epoch 16/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4129 - accuracy: 0.8283 - val_loss: 0.4148 - val_accuracy: 0.8293\n",
      "Epoch 17/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4122 - accuracy: 0.8287 - val_loss: 0.4141 - val_accuracy: 0.8293\n",
      "Epoch 18/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4113 - accuracy: 0.8298 - val_loss: 0.4139 - val_accuracy: 0.8280\n",
      "Epoch 19/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4108 - accuracy: 0.8299 - val_loss: 0.4136 - val_accuracy: 0.8293\n",
      "Epoch 20/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4102 - accuracy: 0.8333 - val_loss: 0.4131 - val_accuracy: 0.8280\n",
      "Epoch 21/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4094 - accuracy: 0.8316 - val_loss: 0.4131 - val_accuracy: 0.8280\n",
      "Epoch 22/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4090 - accuracy: 0.8320 - val_loss: 0.4124 - val_accuracy: 0.8280\n",
      "Epoch 23/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.4086 - accuracy: 0.8323 - val_loss: 0.4120 - val_accuracy: 0.8267\n",
      "Epoch 24/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.4081 - accuracy: 0.8329 - val_loss: 0.4121 - val_accuracy: 0.8293\n",
      "Epoch 25/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.4075 - accuracy: 0.8327 - val_loss: 0.4110 - val_accuracy: 0.8280\n",
      "Epoch 26/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.4070 - accuracy: 0.8345 - val_loss: 0.4110 - val_accuracy: 0.8280\n",
      "Epoch 27/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4067 - accuracy: 0.8364 - val_loss: 0.4111 - val_accuracy: 0.8307\n",
      "Epoch 28/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4065 - accuracy: 0.8345 - val_loss: 0.4103 - val_accuracy: 0.8280\n",
      "Epoch 29/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.4058 - accuracy: 0.8351 - val_loss: 0.4094 - val_accuracy: 0.8280\n",
      "Epoch 30/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4056 - accuracy: 0.8361 - val_loss: 0.4098 - val_accuracy: 0.8280\n",
      "Epoch 31/100\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.4052 - accuracy: 0.8353 - val_loss: 0.4103 - val_accuracy: 0.8240\n",
      "Epoch 32/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4049 - accuracy: 0.8366 - val_loss: 0.4095 - val_accuracy: 0.8267\n",
      "Epoch 33/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4044 - accuracy: 0.8351 - val_loss: 0.4098 - val_accuracy: 0.8240\n",
      "Epoch 34/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4043 - accuracy: 0.8366 - val_loss: 0.4094 - val_accuracy: 0.8253\n",
      "Epoch 35/100\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.4038 - accuracy: 0.8360 - val_loss: 0.4093 - val_accuracy: 0.8253\n",
      "Epoch 36/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4037 - accuracy: 0.8359 - val_loss: 0.4091 - val_accuracy: 0.8240\n",
      "Epoch 37/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4034 - accuracy: 0.8372 - val_loss: 0.4086 - val_accuracy: 0.8253\n",
      "Epoch 38/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.4031 - accuracy: 0.8360 - val_loss: 0.4087 - val_accuracy: 0.8253\n",
      "Epoch 39/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.4029 - accuracy: 0.8360 - val_loss: 0.4083 - val_accuracy: 0.8267\n",
      "Epoch 40/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4026 - accuracy: 0.8379 - val_loss: 0.4089 - val_accuracy: 0.8253\n",
      "Epoch 41/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4024 - accuracy: 0.8378 - val_loss: 0.4083 - val_accuracy: 0.8240\n",
      "Epoch 42/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4023 - accuracy: 0.8366 - val_loss: 0.4086 - val_accuracy: 0.8253\n",
      "Epoch 43/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4020 - accuracy: 0.8369 - val_loss: 0.4090 - val_accuracy: 0.8267\n",
      "Epoch 44/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.4019 - accuracy: 0.8364 - val_loss: 0.4083 - val_accuracy: 0.8253\n",
      "Epoch 45/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.4016 - accuracy: 0.8375 - val_loss: 0.4085 - val_accuracy: 0.8253\n",
      "Epoch 46/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.4013 - accuracy: 0.8372 - val_loss: 0.4079 - val_accuracy: 0.8267\n",
      "Epoch 47/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.4013 - accuracy: 0.8364 - val_loss: 0.4075 - val_accuracy: 0.8253\n",
      "Epoch 48/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4013 - accuracy: 0.8381 - val_loss: 0.4079 - val_accuracy: 0.8253\n",
      "Epoch 49/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4008 - accuracy: 0.8378 - val_loss: 0.4083 - val_accuracy: 0.8253\n",
      "Epoch 50/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4007 - accuracy: 0.8378 - val_loss: 0.4082 - val_accuracy: 0.8253\n",
      "Epoch 51/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4006 - accuracy: 0.8381 - val_loss: 0.4084 - val_accuracy: 0.8253\n",
      "Epoch 52/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4004 - accuracy: 0.8379 - val_loss: 0.4079 - val_accuracy: 0.8267\n",
      "Epoch 53/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4005 - accuracy: 0.8376 - val_loss: 0.4080 - val_accuracy: 0.8280\n",
      "Epoch 54/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4002 - accuracy: 0.8384 - val_loss: 0.4082 - val_accuracy: 0.8267\n",
      "Epoch 55/100\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.4000 - accuracy: 0.8378 - val_loss: 0.4080 - val_accuracy: 0.8280\n",
      "Epoch 56/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.4000 - accuracy: 0.8379 - val_loss: 0.4081 - val_accuracy: 0.8240\n",
      "Epoch 57/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3998 - accuracy: 0.8375 - val_loss: 0.4081 - val_accuracy: 0.8253\n",
      "Epoch 58/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.3999 - accuracy: 0.8376 - val_loss: 0.4079 - val_accuracy: 0.8267\n",
      "Epoch 59/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.3997 - accuracy: 0.8376 - val_loss: 0.4076 - val_accuracy: 0.8253\n",
      "Epoch 60/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3996 - accuracy: 0.8393 - val_loss: 0.4083 - val_accuracy: 0.8280\n",
      "Epoch 61/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.3995 - accuracy: 0.8369 - val_loss: 0.4083 - val_accuracy: 0.8280\n",
      "Epoch 62/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3992 - accuracy: 0.8385 - val_loss: 0.4080 - val_accuracy: 0.8280\n",
      "Epoch 63/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3991 - accuracy: 0.8381 - val_loss: 0.4077 - val_accuracy: 0.8280\n",
      "Epoch 64/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3991 - accuracy: 0.8382 - val_loss: 0.4087 - val_accuracy: 0.8293\n",
      "Epoch 65/100\n",
      "6750/6750 [==============================] - ETA: 0s - loss: 0.4022 - accuracy: 0.83 - 0s 36us/step - loss: 0.3990 - accuracy: 0.8378 - val_loss: 0.4079 - val_accuracy: 0.8280\n",
      "Epoch 66/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3988 - accuracy: 0.8381 - val_loss: 0.4085 - val_accuracy: 0.8293\n",
      "Epoch 67/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3987 - accuracy: 0.8379 - val_loss: 0.4086 - val_accuracy: 0.8293\n",
      "Epoch 68/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3989 - accuracy: 0.8375 - val_loss: 0.4078 - val_accuracy: 0.8293\n",
      "Epoch 69/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3987 - accuracy: 0.8379 - val_loss: 0.4080 - val_accuracy: 0.8280\n",
      "Epoch 70/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3984 - accuracy: 0.8376 - val_loss: 0.4074 - val_accuracy: 0.8293\n",
      "Epoch 71/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3986 - accuracy: 0.8390 - val_loss: 0.4073 - val_accuracy: 0.8293\n",
      "Epoch 72/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.3986 - accuracy: 0.8384 - val_loss: 0.4075 - val_accuracy: 0.8293\n",
      "Epoch 73/100\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.3984 - accuracy: 0.8387 - val_loss: 0.4079 - val_accuracy: 0.8293\n",
      "Epoch 74/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.3983 - accuracy: 0.8381 - val_loss: 0.4091 - val_accuracy: 0.8240\n",
      "Epoch 75/100\n",
      "6750/6750 [==============================] - 0s 35us/step - loss: 0.3983 - accuracy: 0.8387 - val_loss: 0.4082 - val_accuracy: 0.8293\n",
      "Epoch 76/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3982 - accuracy: 0.8393 - val_loss: 0.4085 - val_accuracy: 0.8293\n",
      "Epoch 77/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3981 - accuracy: 0.8378 - val_loss: 0.4089 - val_accuracy: 0.8227\n",
      "Epoch 78/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3981 - accuracy: 0.8387 - val_loss: 0.4088 - val_accuracy: 0.8227\n",
      "Epoch 79/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3980 - accuracy: 0.8379 - val_loss: 0.4075 - val_accuracy: 0.8280\n",
      "Epoch 80/100\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.3979 - accuracy: 0.8382 - val_loss: 0.4080 - val_accuracy: 0.8280\n",
      "Epoch 81/100\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.3977 - accuracy: 0.8388 - val_loss: 0.4082 - val_accuracy: 0.8293\n",
      "Epoch 82/100\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.3976 - accuracy: 0.8385 - val_loss: 0.4075 - val_accuracy: 0.8280\n",
      "Epoch 83/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3978 - accuracy: 0.8387 - val_loss: 0.4076 - val_accuracy: 0.8293\n",
      "Epoch 84/100\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.3978 - accuracy: 0.8387 - val_loss: 0.4078 - val_accuracy: 0.8280\n",
      "Epoch 85/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3976 - accuracy: 0.8384 - val_loss: 0.4088 - val_accuracy: 0.8253\n",
      "Epoch 86/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3979 - accuracy: 0.8384 - val_loss: 0.4088 - val_accuracy: 0.8253\n",
      "Epoch 87/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3976 - accuracy: 0.8381 - val_loss: 0.4084 - val_accuracy: 0.8253\n",
      "Epoch 88/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3977 - accuracy: 0.8387 - val_loss: 0.4086 - val_accuracy: 0.8267\n",
      "Epoch 89/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3975 - accuracy: 0.8382 - val_loss: 0.4085 - val_accuracy: 0.8240\n",
      "Epoch 90/100\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.3974 - accuracy: 0.8387 - val_loss: 0.4080 - val_accuracy: 0.8280\n",
      "Epoch 91/100\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.3975 - accuracy: 0.8388 - val_loss: 0.4075 - val_accuracy: 0.8280\n",
      "Epoch 92/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3973 - accuracy: 0.8378 - val_loss: 0.4080 - val_accuracy: 0.8280\n",
      "Epoch 93/100\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.3974 - accuracy: 0.8388 - val_loss: 0.4086 - val_accuracy: 0.8200\n",
      "Epoch 94/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3973 - accuracy: 0.8384 - val_loss: 0.4085 - val_accuracy: 0.8267\n",
      "Epoch 95/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3972 - accuracy: 0.8379 - val_loss: 0.4085 - val_accuracy: 0.8253\n",
      "Epoch 96/100\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.3971 - accuracy: 0.8378 - val_loss: 0.4092 - val_accuracy: 0.8200\n",
      "Epoch 97/100\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.3975 - accuracy: 0.8378 - val_loss: 0.4088 - val_accuracy: 0.8227\n",
      "Epoch 98/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3973 - accuracy: 0.8382 - val_loss: 0.4097 - val_accuracy: 0.8253\n",
      "Epoch 99/100\n",
      "6750/6750 [==============================] - 0s 37us/step - loss: 0.3975 - accuracy: 0.8388 - val_loss: 0.4085 - val_accuracy: 0.8253\n",
      "Epoch 100/100\n",
      "6750/6750 [==============================] - 0s 36us/step - loss: 0.3971 - accuracy: 0.8385 - val_loss: 0.4089 - val_accuracy: 0.8213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x246e7dc0488>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_model_1.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", \n",
    "                    metrics=[\"accuracy\"])\n",
    "clf_model_1.fit(X_train, y_train, validation_split=0.1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seuil = 0.5\n",
    "y_pred = (clf_model_1.predict(X_test) > seuil)\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap_numbers(cf_matrix, [\"Staying\", \"Leaving\"], \"Simple Hidden Layer NN, confusion matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set : 0.8372\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on test set : {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 6)                 72        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 97\n",
      "Trainable params: 97\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf_model_2 = Sequential()\n",
    "clf_model_2.add(Dense(units=6, activation=\"relu\", \n",
    "                      kernel_initializer=\"uniform\", \n",
    "                      input_dim=X_train.shape[1]))\n",
    "clf_model_2.add(Dense(units=3, activation=\"relu\", \n",
    "                      kernel_initializer=\"uniform\"))\n",
    "clf_model_2.add(Dense(units=1, activation=\"sigmoid\", \n",
    "                      kernel_initializer=\"uniform\"))\n",
    "clf_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/100\n",
      "6750/6750 [==============================] - 0s 61us/step - loss: 0.5967 - accuracy: 0.7945 - val_loss: 0.4622 - val_accuracy: 0.7987\n",
      "Epoch 2/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.4407 - accuracy: 0.7945 - val_loss: 0.4323 - val_accuracy: 0.7987\n",
      "Epoch 3/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4318 - accuracy: 0.7945 - val_loss: 0.4287 - val_accuracy: 0.7987\n",
      "Epoch 4/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.4283 - accuracy: 0.7945 - val_loss: 0.4260 - val_accuracy: 0.7987\n",
      "Epoch 5/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4256 - accuracy: 0.7945 - val_loss: 0.4234 - val_accuracy: 0.7987\n",
      "Epoch 6/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.4234 - accuracy: 0.7945 - val_loss: 0.4213 - val_accuracy: 0.7987\n",
      "Epoch 7/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.4214 - accuracy: 0.7945 - val_loss: 0.4207 - val_accuracy: 0.7987\n",
      "Epoch 8/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.4197 - accuracy: 0.8015 - val_loss: 0.4177 - val_accuracy: 0.8173\n",
      "Epoch 9/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4182 - accuracy: 0.8191 - val_loss: 0.4169 - val_accuracy: 0.8213\n",
      "Epoch 10/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.4169 - accuracy: 0.8224 - val_loss: 0.4163 - val_accuracy: 0.8187\n",
      "Epoch 11/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.4159 - accuracy: 0.8241 - val_loss: 0.4157 - val_accuracy: 0.8160\n",
      "Epoch 12/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.4148 - accuracy: 0.8279 - val_loss: 0.4145 - val_accuracy: 0.8187\n",
      "Epoch 13/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4140 - accuracy: 0.8293 - val_loss: 0.4141 - val_accuracy: 0.8227\n",
      "Epoch 14/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4130 - accuracy: 0.8311 - val_loss: 0.4130 - val_accuracy: 0.8240\n",
      "Epoch 15/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.4120 - accuracy: 0.8289 - val_loss: 0.4137 - val_accuracy: 0.8253\n",
      "Epoch 16/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4116 - accuracy: 0.8317 - val_loss: 0.4132 - val_accuracy: 0.8253\n",
      "Epoch 17/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.4108 - accuracy: 0.8314 - val_loss: 0.4108 - val_accuracy: 0.8267\n",
      "Epoch 18/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4097 - accuracy: 0.8326 - val_loss: 0.4117 - val_accuracy: 0.8320\n",
      "Epoch 19/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4094 - accuracy: 0.8330 - val_loss: 0.4114 - val_accuracy: 0.8320\n",
      "Epoch 20/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4086 - accuracy: 0.8330 - val_loss: 0.4102 - val_accuracy: 0.8320\n",
      "Epoch 21/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.4079 - accuracy: 0.8344 - val_loss: 0.4105 - val_accuracy: 0.8280\n",
      "Epoch 22/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.4074 - accuracy: 0.8347 - val_loss: 0.4103 - val_accuracy: 0.8307\n",
      "Epoch 23/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4068 - accuracy: 0.8363 - val_loss: 0.4091 - val_accuracy: 0.8280\n",
      "Epoch 24/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4065 - accuracy: 0.8357 - val_loss: 0.4094 - val_accuracy: 0.8280\n",
      "Epoch 25/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.4054 - accuracy: 0.8357 - val_loss: 0.4100 - val_accuracy: 0.8240\n",
      "Epoch 26/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4053 - accuracy: 0.8373 - val_loss: 0.4093 - val_accuracy: 0.8240\n",
      "Epoch 27/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.4045 - accuracy: 0.8360 - val_loss: 0.4098 - val_accuracy: 0.8253\n",
      "Epoch 28/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4044 - accuracy: 0.8369 - val_loss: 0.4091 - val_accuracy: 0.8253\n",
      "Epoch 29/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4035 - accuracy: 0.8373 - val_loss: 0.4095 - val_accuracy: 0.8240\n",
      "Epoch 30/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4038 - accuracy: 0.8376 - val_loss: 0.4084 - val_accuracy: 0.8253\n",
      "Epoch 31/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.4033 - accuracy: 0.8373 - val_loss: 0.4079 - val_accuracy: 0.8267\n",
      "Epoch 32/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4030 - accuracy: 0.8372 - val_loss: 0.4082 - val_accuracy: 0.8227\n",
      "Epoch 33/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4027 - accuracy: 0.8372 - val_loss: 0.4081 - val_accuracy: 0.8280\n",
      "Epoch 34/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4026 - accuracy: 0.8373 - val_loss: 0.4077 - val_accuracy: 0.8267\n",
      "Epoch 35/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4019 - accuracy: 0.8378 - val_loss: 0.4073 - val_accuracy: 0.8253\n",
      "Epoch 36/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4020 - accuracy: 0.8373 - val_loss: 0.4077 - val_accuracy: 0.8280\n",
      "Epoch 37/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4014 - accuracy: 0.8370 - val_loss: 0.4091 - val_accuracy: 0.8293\n",
      "Epoch 38/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4015 - accuracy: 0.8378 - val_loss: 0.4085 - val_accuracy: 0.8267\n",
      "Epoch 39/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4015 - accuracy: 0.8387 - val_loss: 0.4075 - val_accuracy: 0.8293\n",
      "Epoch 40/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4011 - accuracy: 0.8375 - val_loss: 0.4078 - val_accuracy: 0.8280\n",
      "Epoch 41/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4009 - accuracy: 0.8376 - val_loss: 0.4082 - val_accuracy: 0.8280\n",
      "Epoch 42/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.4007 - accuracy: 0.8384 - val_loss: 0.4068 - val_accuracy: 0.8293\n",
      "Epoch 43/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4008 - accuracy: 0.8369 - val_loss: 0.4065 - val_accuracy: 0.8280\n",
      "Epoch 44/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.4005 - accuracy: 0.8390 - val_loss: 0.4063 - val_accuracy: 0.8293\n",
      "Epoch 45/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4002 - accuracy: 0.8384 - val_loss: 0.4071 - val_accuracy: 0.8280\n",
      "Epoch 46/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4001 - accuracy: 0.8385 - val_loss: 0.4079 - val_accuracy: 0.8293\n",
      "Epoch 47/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3998 - accuracy: 0.8378 - val_loss: 0.4071 - val_accuracy: 0.8320\n",
      "Epoch 48/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4000 - accuracy: 0.8376 - val_loss: 0.4078 - val_accuracy: 0.8227\n",
      "Epoch 49/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3997 - accuracy: 0.8394 - val_loss: 0.4076 - val_accuracy: 0.8227\n",
      "Epoch 50/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3995 - accuracy: 0.8382 - val_loss: 0.4067 - val_accuracy: 0.8267\n",
      "Epoch 51/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3994 - accuracy: 0.8381 - val_loss: 0.4060 - val_accuracy: 0.8307\n",
      "Epoch 52/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3992 - accuracy: 0.8387 - val_loss: 0.4078 - val_accuracy: 0.8267\n",
      "Epoch 53/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3998 - accuracy: 0.8373 - val_loss: 0.4064 - val_accuracy: 0.8293\n",
      "Epoch 54/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3991 - accuracy: 0.8394 - val_loss: 0.4069 - val_accuracy: 0.8267\n",
      "Epoch 55/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3992 - accuracy: 0.8396 - val_loss: 0.4067 - val_accuracy: 0.8253\n",
      "Epoch 56/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3989 - accuracy: 0.8375 - val_loss: 0.4067 - val_accuracy: 0.8267\n",
      "Epoch 57/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3988 - accuracy: 0.8391 - val_loss: 0.4060 - val_accuracy: 0.8280\n",
      "Epoch 58/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3988 - accuracy: 0.8384 - val_loss: 0.4070 - val_accuracy: 0.8267\n",
      "Epoch 59/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3985 - accuracy: 0.8379 - val_loss: 0.4070 - val_accuracy: 0.8293\n",
      "Epoch 60/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3984 - accuracy: 0.8388 - val_loss: 0.4060 - val_accuracy: 0.8293\n",
      "Epoch 61/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3989 - accuracy: 0.8381 - val_loss: 0.4059 - val_accuracy: 0.8307\n",
      "Epoch 62/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3984 - accuracy: 0.8391 - val_loss: 0.4064 - val_accuracy: 0.8293\n",
      "Epoch 63/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3982 - accuracy: 0.8394 - val_loss: 0.4080 - val_accuracy: 0.8253\n",
      "Epoch 64/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3983 - accuracy: 0.8385 - val_loss: 0.4063 - val_accuracy: 0.8267\n",
      "Epoch 65/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3982 - accuracy: 0.8384 - val_loss: 0.4066 - val_accuracy: 0.8267\n",
      "Epoch 66/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3983 - accuracy: 0.8388 - val_loss: 0.4070 - val_accuracy: 0.8267\n",
      "Epoch 67/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3981 - accuracy: 0.8367 - val_loss: 0.4068 - val_accuracy: 0.8280\n",
      "Epoch 68/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3980 - accuracy: 0.8388 - val_loss: 0.4068 - val_accuracy: 0.8280\n",
      "Epoch 69/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3979 - accuracy: 0.8379 - val_loss: 0.4059 - val_accuracy: 0.8293\n",
      "Epoch 70/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3979 - accuracy: 0.8387 - val_loss: 0.4086 - val_accuracy: 0.8240\n",
      "Epoch 71/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3974 - accuracy: 0.8385 - val_loss: 0.4088 - val_accuracy: 0.8267\n",
      "Epoch 72/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3977 - accuracy: 0.8404 - val_loss: 0.4081 - val_accuracy: 0.8280\n",
      "Epoch 73/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3976 - accuracy: 0.8396 - val_loss: 0.4072 - val_accuracy: 0.8293\n",
      "Epoch 74/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3973 - accuracy: 0.8390 - val_loss: 0.4091 - val_accuracy: 0.8240\n",
      "Epoch 75/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3977 - accuracy: 0.8372 - val_loss: 0.4093 - val_accuracy: 0.8227\n",
      "Epoch 76/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3977 - accuracy: 0.8393 - val_loss: 0.4071 - val_accuracy: 0.8280\n",
      "Epoch 77/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3970 - accuracy: 0.8387 - val_loss: 0.4080 - val_accuracy: 0.8280\n",
      "Epoch 78/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3975 - accuracy: 0.8394 - val_loss: 0.4074 - val_accuracy: 0.8240\n",
      "Epoch 79/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3971 - accuracy: 0.8382 - val_loss: 0.4078 - val_accuracy: 0.8280\n",
      "Epoch 80/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3975 - accuracy: 0.8394 - val_loss: 0.4067 - val_accuracy: 0.8293\n",
      "Epoch 81/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3972 - accuracy: 0.8415 - val_loss: 0.4082 - val_accuracy: 0.8253\n",
      "Epoch 82/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3970 - accuracy: 0.8379 - val_loss: 0.4101 - val_accuracy: 0.8240\n",
      "Epoch 83/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3975 - accuracy: 0.8393 - val_loss: 0.4075 - val_accuracy: 0.8293\n",
      "Epoch 84/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3970 - accuracy: 0.8394 - val_loss: 0.4074 - val_accuracy: 0.8253\n",
      "Epoch 85/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3972 - accuracy: 0.8372 - val_loss: 0.4080 - val_accuracy: 0.8280\n",
      "Epoch 86/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3972 - accuracy: 0.8391 - val_loss: 0.4085 - val_accuracy: 0.8280\n",
      "Epoch 87/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3973 - accuracy: 0.8399 - val_loss: 0.4078 - val_accuracy: 0.8213\n",
      "Epoch 88/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3969 - accuracy: 0.8393 - val_loss: 0.4078 - val_accuracy: 0.8227\n",
      "Epoch 89/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3968 - accuracy: 0.8382 - val_loss: 0.4075 - val_accuracy: 0.8280\n",
      "Epoch 90/100\n",
      "6750/6750 [==============================] - 0s 45us/step - loss: 0.3970 - accuracy: 0.8401 - val_loss: 0.4076 - val_accuracy: 0.8267\n",
      "Epoch 91/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3968 - accuracy: 0.8384 - val_loss: 0.4090 - val_accuracy: 0.8227\n",
      "Epoch 92/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3971 - accuracy: 0.8372 - val_loss: 0.4082 - val_accuracy: 0.8213\n",
      "Epoch 93/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3971 - accuracy: 0.8387 - val_loss: 0.4068 - val_accuracy: 0.8293\n",
      "Epoch 94/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3967 - accuracy: 0.8384 - val_loss: 0.4060 - val_accuracy: 0.8307\n",
      "Epoch 95/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3968 - accuracy: 0.8399 - val_loss: 0.4079 - val_accuracy: 0.8213\n",
      "Epoch 96/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3970 - accuracy: 0.8372 - val_loss: 0.4074 - val_accuracy: 0.8293\n",
      "Epoch 97/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3969 - accuracy: 0.8393 - val_loss: 0.4071 - val_accuracy: 0.8267\n",
      "Epoch 98/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3971 - accuracy: 0.8388 - val_loss: 0.4078 - val_accuracy: 0.8240\n",
      "Epoch 99/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3970 - accuracy: 0.8390 - val_loss: 0.4076 - val_accuracy: 0.8213\n",
      "Epoch 100/100\n",
      "6750/6750 [==============================] - 0s 41us/step - loss: 0.3968 - accuracy: 0.8394 - val_loss: 0.4068 - val_accuracy: 0.8240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x246e9b1ec08>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_model_2.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", \n",
    "                    metrics=[\"accuracy\"])\n",
    "clf_model_2.fit(X_train.values, y_train, validation_split=0.1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "seuil = 0.5\n",
    "y_pred = (clf_model_2.predict(X_test) > seuil)\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap_numbers(cf_matrix, [\"Staying\", \"Leaving\"], \"Multi Hidden Layer NN, confusion matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set : 0.8328\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on test set : {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Hidden Layer Increased\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf_model_3 = Sequential()\n",
    "clf_model_3.add(Dense(units=10, activation=\"relu\", \n",
    "                      kernel_initializer=\"uniform\", \n",
    "                      input_dim=X_train.shape[1]))\n",
    "clf_model_3.add(Dense(units=6, activation=\"relu\", \n",
    "                      kernel_initializer=\"uniform\"))\n",
    "clf_model_3.add(Dense(units=1, activation=\"sigmoid\", \n",
    "                      kernel_initializer=\"uniform\"))\n",
    "clf_model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6750 samples, validate on 750 samples\n",
      "Epoch 1/100\n",
      "6750/6750 [==============================] - 0s 61us/step - loss: 0.5757 - accuracy: 0.7942 - val_loss: 0.4379 - val_accuracy: 0.7987\n",
      "Epoch 2/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.4324 - accuracy: 0.7945 - val_loss: 0.4246 - val_accuracy: 0.7987\n",
      "Epoch 3/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.4246 - accuracy: 0.7945 - val_loss: 0.4233 - val_accuracy: 0.7987\n",
      "Epoch 4/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.4195 - accuracy: 0.7945 - val_loss: 0.4191 - val_accuracy: 0.7987\n",
      "Epoch 5/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4146 - accuracy: 0.7945 - val_loss: 0.4143 - val_accuracy: 0.7987\n",
      "Epoch 6/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.4098 - accuracy: 0.7945 - val_loss: 0.4108 - val_accuracy: 0.7987\n",
      "Epoch 7/100\n",
      "6750/6750 [==============================] - 0s 42us/step - loss: 0.4045 - accuracy: 0.8030 - val_loss: 0.4061 - val_accuracy: 0.8200\n",
      "Epoch 8/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3994 - accuracy: 0.8301 - val_loss: 0.4007 - val_accuracy: 0.8200\n",
      "Epoch 9/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3941 - accuracy: 0.8320 - val_loss: 0.3965 - val_accuracy: 0.8253\n",
      "Epoch 10/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3892 - accuracy: 0.8314 - val_loss: 0.3951 - val_accuracy: 0.8280\n",
      "Epoch 11/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3844 - accuracy: 0.8310 - val_loss: 0.3903 - val_accuracy: 0.8240\n",
      "Epoch 12/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3807 - accuracy: 0.8332 - val_loss: 0.3875 - val_accuracy: 0.8373\n",
      "Epoch 13/100\n",
      "6750/6750 [==============================] - 0s 42us/step - loss: 0.3768 - accuracy: 0.8421 - val_loss: 0.3881 - val_accuracy: 0.8347\n",
      "Epoch 14/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3739 - accuracy: 0.8446 - val_loss: 0.3850 - val_accuracy: 0.8427\n",
      "Epoch 15/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3705 - accuracy: 0.8481 - val_loss: 0.3851 - val_accuracy: 0.8480\n",
      "Epoch 16/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3683 - accuracy: 0.8501 - val_loss: 0.3787 - val_accuracy: 0.8467\n",
      "Epoch 17/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3650 - accuracy: 0.8511 - val_loss: 0.3807 - val_accuracy: 0.8453\n",
      "Epoch 18/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3635 - accuracy: 0.8533 - val_loss: 0.3782 - val_accuracy: 0.8467\n",
      "Epoch 19/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3614 - accuracy: 0.8542 - val_loss: 0.3801 - val_accuracy: 0.8480\n",
      "Epoch 20/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3597 - accuracy: 0.8533 - val_loss: 0.3766 - val_accuracy: 0.8453\n",
      "Epoch 21/100\n",
      "6750/6750 [==============================] - 0s 43us/step - loss: 0.3580 - accuracy: 0.8563 - val_loss: 0.3785 - val_accuracy: 0.8493\n",
      "Epoch 22/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3569 - accuracy: 0.8563 - val_loss: 0.3744 - val_accuracy: 0.8587\n",
      "Epoch 23/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3555 - accuracy: 0.8539 - val_loss: 0.3799 - val_accuracy: 0.8573\n",
      "Epoch 24/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3549 - accuracy: 0.8563 - val_loss: 0.3802 - val_accuracy: 0.8547\n",
      "Epoch 25/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3529 - accuracy: 0.8579 - val_loss: 0.3760 - val_accuracy: 0.8533\n",
      "Epoch 26/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3523 - accuracy: 0.8596 - val_loss: 0.3729 - val_accuracy: 0.8573\n",
      "Epoch 27/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3513 - accuracy: 0.8578 - val_loss: 0.3751 - val_accuracy: 0.8533\n",
      "Epoch 28/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3508 - accuracy: 0.8570 - val_loss: 0.3752 - val_accuracy: 0.8507\n",
      "Epoch 29/100\n",
      "6750/6750 [==============================] - 0s 41us/step - loss: 0.3504 - accuracy: 0.8584 - val_loss: 0.3736 - val_accuracy: 0.8667\n",
      "Epoch 30/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3496 - accuracy: 0.8601 - val_loss: 0.3726 - val_accuracy: 0.8587\n",
      "Epoch 31/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3485 - accuracy: 0.8594 - val_loss: 0.3793 - val_accuracy: 0.8587\n",
      "Epoch 32/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3476 - accuracy: 0.8600 - val_loss: 0.3756 - val_accuracy: 0.8560\n",
      "Epoch 33/100\n",
      "6750/6750 [==============================] - 0s 41us/step - loss: 0.3479 - accuracy: 0.8604 - val_loss: 0.3769 - val_accuracy: 0.8573\n",
      "Epoch 34/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3473 - accuracy: 0.8593 - val_loss: 0.3728 - val_accuracy: 0.8573\n",
      "Epoch 35/100\n",
      "6750/6750 [==============================] - 0s 42us/step - loss: 0.3466 - accuracy: 0.8590 - val_loss: 0.3726 - val_accuracy: 0.8533\n",
      "Epoch 36/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3454 - accuracy: 0.8582 - val_loss: 0.3751 - val_accuracy: 0.8573\n",
      "Epoch 37/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3460 - accuracy: 0.8603 - val_loss: 0.3765 - val_accuracy: 0.8520\n",
      "Epoch 38/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3454 - accuracy: 0.8610 - val_loss: 0.3769 - val_accuracy: 0.8453\n",
      "Epoch 39/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3449 - accuracy: 0.8573 - val_loss: 0.3708 - val_accuracy: 0.8520\n",
      "Epoch 40/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3440 - accuracy: 0.8597 - val_loss: 0.3754 - val_accuracy: 0.8560\n",
      "Epoch 41/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3443 - accuracy: 0.8613 - val_loss: 0.3735 - val_accuracy: 0.8547\n",
      "Epoch 42/100\n",
      "6750/6750 [==============================] - 0s 41us/step - loss: 0.3440 - accuracy: 0.8594 - val_loss: 0.3734 - val_accuracy: 0.8440\n",
      "Epoch 43/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3442 - accuracy: 0.8593 - val_loss: 0.3722 - val_accuracy: 0.8560\n",
      "Epoch 44/100\n",
      "6750/6750 [==============================] - 0s 42us/step - loss: 0.3438 - accuracy: 0.8564 - val_loss: 0.3743 - val_accuracy: 0.8560\n",
      "Epoch 45/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3433 - accuracy: 0.8590 - val_loss: 0.3693 - val_accuracy: 0.8480\n",
      "Epoch 46/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3424 - accuracy: 0.8593 - val_loss: 0.3739 - val_accuracy: 0.8480\n",
      "Epoch 47/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3425 - accuracy: 0.8596 - val_loss: 0.3727 - val_accuracy: 0.8613\n",
      "Epoch 48/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3426 - accuracy: 0.8601 - val_loss: 0.3735 - val_accuracy: 0.8467\n",
      "Epoch 49/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3420 - accuracy: 0.8590 - val_loss: 0.3720 - val_accuracy: 0.8587\n",
      "Epoch 50/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3417 - accuracy: 0.8610 - val_loss: 0.3710 - val_accuracy: 0.8547\n",
      "Epoch 51/100\n",
      "6750/6750 [==============================] - 0s 44us/step - loss: 0.3420 - accuracy: 0.8609 - val_loss: 0.3711 - val_accuracy: 0.8533\n",
      "Epoch 52/100\n",
      "6750/6750 [==============================] - 0s 44us/step - loss: 0.3415 - accuracy: 0.8594 - val_loss: 0.3740 - val_accuracy: 0.8547\n",
      "Epoch 53/100\n",
      "6750/6750 [==============================] - 0s 43us/step - loss: 0.3412 - accuracy: 0.8607 - val_loss: 0.3725 - val_accuracy: 0.8507\n",
      "Epoch 54/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3403 - accuracy: 0.8622 - val_loss: 0.3751 - val_accuracy: 0.8493\n",
      "Epoch 55/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3400 - accuracy: 0.8607 - val_loss: 0.3701 - val_accuracy: 0.8493\n",
      "Epoch 56/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3420 - accuracy: 0.8607 - val_loss: 0.3711 - val_accuracy: 0.8613\n",
      "Epoch 57/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3399 - accuracy: 0.8607 - val_loss: 0.3743 - val_accuracy: 0.8560\n",
      "Epoch 58/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3406 - accuracy: 0.8596 - val_loss: 0.3752 - val_accuracy: 0.8427\n",
      "Epoch 59/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3400 - accuracy: 0.8618 - val_loss: 0.3782 - val_accuracy: 0.8427\n",
      "Epoch 60/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3399 - accuracy: 0.8599 - val_loss: 0.3744 - val_accuracy: 0.8493\n",
      "Epoch 61/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3406 - accuracy: 0.8613 - val_loss: 0.3713 - val_accuracy: 0.8573\n",
      "Epoch 62/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3402 - accuracy: 0.8628 - val_loss: 0.3732 - val_accuracy: 0.8480\n",
      "Epoch 63/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3394 - accuracy: 0.8618 - val_loss: 0.3703 - val_accuracy: 0.8453\n",
      "Epoch 64/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3394 - accuracy: 0.8613 - val_loss: 0.3690 - val_accuracy: 0.8520\n",
      "Epoch 65/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3388 - accuracy: 0.8609 - val_loss: 0.3721 - val_accuracy: 0.8533\n",
      "Epoch 66/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3393 - accuracy: 0.8604 - val_loss: 0.3732 - val_accuracy: 0.8533\n",
      "Epoch 67/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3392 - accuracy: 0.8591 - val_loss: 0.3708 - val_accuracy: 0.8533\n",
      "Epoch 68/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3388 - accuracy: 0.8593 - val_loss: 0.3693 - val_accuracy: 0.8573\n",
      "Epoch 69/100\n",
      "6750/6750 [==============================] - 0s 41us/step - loss: 0.3397 - accuracy: 0.8564 - val_loss: 0.3725 - val_accuracy: 0.8547\n",
      "Epoch 70/100\n",
      "6750/6750 [==============================] - 0s 42us/step - loss: 0.3384 - accuracy: 0.8590 - val_loss: 0.3806 - val_accuracy: 0.8387\n",
      "Epoch 71/100\n",
      "6750/6750 [==============================] - 0s 41us/step - loss: 0.3383 - accuracy: 0.8625 - val_loss: 0.3720 - val_accuracy: 0.8560\n",
      "Epoch 72/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3384 - accuracy: 0.8628 - val_loss: 0.3776 - val_accuracy: 0.8400\n",
      "Epoch 73/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3393 - accuracy: 0.8609 - val_loss: 0.3735 - val_accuracy: 0.8520\n",
      "Epoch 74/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3387 - accuracy: 0.8610 - val_loss: 0.3681 - val_accuracy: 0.8507\n",
      "Epoch 75/100\n",
      "6750/6750 [==============================] - 0s 40us/step - loss: 0.3385 - accuracy: 0.8616 - val_loss: 0.3708 - val_accuracy: 0.8547\n",
      "Epoch 76/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3377 - accuracy: 0.8582 - val_loss: 0.3724 - val_accuracy: 0.8507\n",
      "Epoch 77/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3384 - accuracy: 0.8597 - val_loss: 0.3686 - val_accuracy: 0.8560\n",
      "Epoch 78/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3382 - accuracy: 0.8603 - val_loss: 0.3681 - val_accuracy: 0.8573\n",
      "Epoch 79/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3393 - accuracy: 0.8596 - val_loss: 0.3696 - val_accuracy: 0.8507\n",
      "Epoch 80/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3393 - accuracy: 0.8594 - val_loss: 0.3686 - val_accuracy: 0.8547\n",
      "Epoch 81/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3381 - accuracy: 0.8618 - val_loss: 0.3738 - val_accuracy: 0.8560\n",
      "Epoch 82/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3388 - accuracy: 0.8604 - val_loss: 0.3719 - val_accuracy: 0.8440\n",
      "Epoch 83/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3367 - accuracy: 0.8619 - val_loss: 0.3710 - val_accuracy: 0.8507\n",
      "Epoch 84/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3378 - accuracy: 0.8591 - val_loss: 0.3688 - val_accuracy: 0.8493\n",
      "Epoch 85/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3378 - accuracy: 0.8613 - val_loss: 0.3701 - val_accuracy: 0.8480\n",
      "Epoch 86/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3372 - accuracy: 0.8601 - val_loss: 0.3713 - val_accuracy: 0.8533\n",
      "Epoch 87/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3385 - accuracy: 0.8599 - val_loss: 0.3763 - val_accuracy: 0.8493\n",
      "Epoch 88/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3373 - accuracy: 0.8599 - val_loss: 0.3729 - val_accuracy: 0.8453\n",
      "Epoch 89/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3375 - accuracy: 0.8612 - val_loss: 0.3745 - val_accuracy: 0.8520\n",
      "Epoch 90/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3376 - accuracy: 0.8594 - val_loss: 0.3682 - val_accuracy: 0.8560\n",
      "Epoch 91/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3378 - accuracy: 0.8610 - val_loss: 0.3676 - val_accuracy: 0.8640\n",
      "Epoch 92/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3368 - accuracy: 0.8596 - val_loss: 0.3690 - val_accuracy: 0.8520\n",
      "Epoch 93/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3377 - accuracy: 0.8615 - val_loss: 0.3760 - val_accuracy: 0.8520\n",
      "Epoch 94/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3380 - accuracy: 0.8627 - val_loss: 0.3753 - val_accuracy: 0.8440\n",
      "Epoch 95/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3373 - accuracy: 0.8607 - val_loss: 0.3757 - val_accuracy: 0.8387\n",
      "Epoch 96/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3375 - accuracy: 0.8607 - val_loss: 0.3790 - val_accuracy: 0.8400\n",
      "Epoch 97/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3382 - accuracy: 0.8615 - val_loss: 0.3699 - val_accuracy: 0.8600\n",
      "Epoch 98/100\n",
      "6750/6750 [==============================] - 0s 38us/step - loss: 0.3361 - accuracy: 0.8621 - val_loss: 0.3781 - val_accuracy: 0.8480\n",
      "Epoch 99/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3375 - accuracy: 0.8600 - val_loss: 0.3688 - val_accuracy: 0.8587\n",
      "Epoch 100/100\n",
      "6750/6750 [==============================] - 0s 39us/step - loss: 0.3371 - accuracy: 0.8601 - val_loss: 0.3713 - val_accuracy: 0.8480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x246eab63dc8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_model_3.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", \n",
    "                    metrics=[\"accuracy\"])\n",
    "clf_model_3.fit(X_train.values, y_train, validation_split=0.1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "seuil = 0.5\n",
    "y_pred = (clf_model_3.predict(X_test) > seuil)\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap_numbers(cf_matrix, [\"Staying\", \"Leaving\"], \"Multi Hidden Improved Layer NN, confusion matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set : 0.8556\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on test set : {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "Now that we have done some basic neural networks tests, we are going to try a more advanced method which is cross validation (K-Fold).\n",
    "\n",
    "We seek for a low variance(regularity in training) and a low biais (good accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    clf_model = Sequential()\n",
    "    clf_model.add(Dense(units=10, activation=\"relu\", \n",
    "                          kernel_initializer=\"uniform\", \n",
    "                          input_dim=X_train.shape[1]))\n",
    "    clf_model.add(Dense(units=6, activation=\"relu\", \n",
    "                          kernel_initializer=\"uniform\"))\n",
    "    clf_model.add(Dense(units=1, activation=\"sigmoid\", \n",
    "                          kernel_initializer=\"uniform\"))\n",
    "    clf_model.summary()\n",
    "    clf_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", \n",
    "                    metrics=[\"accuracy\"])\n",
    "    return clf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1 = KerasClassifier(build_fn=build_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:    6.5s remaining:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    8.2s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    8.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    8.3s finished\n"
     ]
    }
   ],
   "source": [
    "k_fold_scores = cross_val_score(clf_1, X=X_train, y=y_train, cv=10, \n",
    "                                 verbose=4, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.795"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold_scores.mean().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fold_scores.std().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "We will explore here a way to counterbalance overfitting called dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf_model = Sequential()\n",
    "clf_model.add(Dense(units=10, activation=\"relu\", \n",
    "                          kernel_initializer=\"uniform\", \n",
    "                          input_dim=X_train.shape[1]))\n",
    "clf_model.add(Dropout(rate=0.1))\n",
    "clf_model.add(Dense(units=6, activation=\"relu\", \n",
    "                          kernel_initializer=\"uniform\"))\n",
    "clf_model.add(Dropout(rate=0.1))\n",
    "clf_model.add(Dense(units=1, activation=\"sigmoid\", \n",
    "                          kernel_initializer=\"uniform\"))\n",
    "clf_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve by increasing hyperparameters\n",
    "\n",
    "Using gridsearch or randomsearch to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(input_dim, layers_nb, function, kernel_init, optimizer):\n",
    "    clf_model = Sequential()\n",
    "    layers_nb = layers_nb.split(\"-\")\n",
    "    for i in range(len(layers_nb)):\n",
    "        if i == 0:\n",
    "            clf_model.add(Dense(units=int(layers_nb[i]), activation=\"relu\", \n",
    "                          kernel_initializer=kernel_init, \n",
    "                          input_dim=input_dim))\n",
    "        elif i == len(layers_nb) - 1:\n",
    "            clf_model.add(Dense(units=int(layers_nb[i]), activation=function, \n",
    "                          kernel_initializer=kernel_init))\n",
    "        else:\n",
    "            clf_model.add(Dense(units=int(layers_nb[i]), activation=\"relu\", \n",
    "                          kernel_initializer=kernel_init))\n",
    "    clf_model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", \n",
    "                    metrics=[\"accuracy\"])\n",
    "    return clf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_nb = []\n",
    "for i in range(3,11):\n",
    "    # single-layer\n",
    "    layer_nb.append(\"{}-1\".format(i))\n",
    "    # multi-layer\n",
    "    for j in range(2,i+1):\n",
    "        layer_nb.append(\"{}-{}-1\".format(i,j))\n",
    "\n",
    "params = {\n",
    "    \"epochs\": range(20,101,20),\n",
    "    \"optimizer\":[\"adam\", \"rmsprop\"],\n",
    "    \"function\":[\"sigmoid\"],\n",
    "    \"kernel_init\":[\"uniform\"],\n",
    "    \"input_dim\":[X_train.shape[1]],\n",
    "    \"layers_nb\":layer_nb\n",
    "}\n",
    "clf_1 = KerasClassifier(build_fn=build_classifier)\n",
    "rs_cv = RandomizedSearchCV(estimator=clf_1, param_distributions=params, \n",
    "                           scoring=\"accuracy\", cv=10, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 0.6598 - accuracy: 0.7933\n",
      "Epoch 2/40\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.6068 - accuracy: 0.7949\n",
      "Epoch 3/40\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.5637 - accuracy: 0.7949\n",
      "Epoch 4/40\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.5259 - accuracy: 0.7951\n",
      "Epoch 5/40\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4922 - accuracy: 0.8131\n",
      "Epoch 6/40\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4653 - accuracy: 0.8256\n",
      "Epoch 7/40\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4465 - accuracy: 0.8315\n",
      "Epoch 8/40\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4344 - accuracy: 0.8325\n",
      "Epoch 9/40\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4272 - accuracy: 0.8349\n",
      "Epoch 10/40\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4224 - accuracy: 0.8353\n",
      "Epoch 11/40\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4195 - accuracy: 0.8344\n",
      "Epoch 12/40\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4173 - accuracy: 0.8361\n",
      "Epoch 13/40\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4157 - accuracy: 0.8356\n",
      "Epoch 14/40\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4147 - accuracy: 0.8356\n",
      "Epoch 15/40\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.4136 - accuracy: 0.8355\n",
      "Epoch 16/40\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.4126 - accuracy: 0.8371\n",
      "Epoch 17/40\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4118 - accuracy: 0.8363\n",
      "Epoch 18/40\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4114 - accuracy: 0.8369\n",
      "Epoch 19/40\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4108 - accuracy: 0.8364\n",
      "Epoch 20/40\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4102 - accuracy: 0.8361\n",
      "Epoch 21/40\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4092 - accuracy: 0.8383\n",
      "Epoch 22/40\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.4091 - accuracy: 0.8376\n",
      "Epoch 23/40\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4087 - accuracy: 0.8375\n",
      "Epoch 24/40\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4083 - accuracy: 0.8376\n",
      "Epoch 25/40\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4082 - accuracy: 0.8377\n",
      "Epoch 26/40\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4078 - accuracy: 0.8383\n",
      "Epoch 27/40\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4074 - accuracy: 0.8380\n",
      "Epoch 28/40\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4068 - accuracy: 0.8384\n",
      "Epoch 29/40\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4061 - accuracy: 0.8381\n",
      "Epoch 30/40\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4057 - accuracy: 0.8383\n",
      "Epoch 31/40\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4050 - accuracy: 0.8389\n",
      "Epoch 32/40\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4041 - accuracy: 0.8389\n",
      "Epoch 33/40\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4021 - accuracy: 0.8376\n",
      "Epoch 34/40\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.3996 - accuracy: 0.8376\n",
      "Epoch 35/40\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.3968 - accuracy: 0.8384\n",
      "Epoch 36/40\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.3933 - accuracy: 0.8391\n",
      "Epoch 37/40\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3889 - accuracy: 0.8407\n",
      "Epoch 38/40\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.3851 - accuracy: 0.8421\n",
      "Epoch 39/40\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.3811 - accuracy: 0.8451\n",
      "Epoch 40/40\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3774 - accuracy: 0.8465\n"
     ]
    }
   ],
   "source": [
    "rs_cv = rs_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': 'rmsprop',\n",
       " 'layers_nb': '10-2-1',\n",
       " 'kernel_init': 'uniform',\n",
       " 'input_dim': 11,\n",
       " 'function': 'sigmoid',\n",
       " 'epochs': 40}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8492"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reached a best score of 0.85 using the previous parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
