{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Encoder\n",
    "\n",
    "This notebook was created by Camille-Amaury JUGE, in order to better understand Auto Encoder principles and how they work.\n",
    "\n",
    "(it follows the exercices proposed by Hadelin de Ponteves on Udemy : https://www.udemy.com/course/le-deep-learning-de-a-a-z/)\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sys\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "same process as Boltzmann's machine (go there to see more details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv(\"ml-1m\\\\movies.dat\", sep=\"::\", header=None, engine=\"python\",\n",
    "                encoding=\"latin-1\")\n",
    "users = pd.read_csv(\"ml-1m\\\\users.dat\", sep=\"::\", header=None, engine=\"python\",\n",
    "                encoding=\"latin-1\")\n",
    "ratings = pd.read_csv(\"ml-1m\\\\ratings.dat\", sep=\"::\", header=None, engine=\"python\",\n",
    "                encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"ml-100k\\\\u1.base\", delimiter=\"\\t\", header=None)\n",
    "df_test = pd.read_csv(\"ml-100k\\\\u1.test\", delimiter=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_users = list(set(np.concatenate((df_train[df_train.columns[0]].value_counts().index, \n",
    "                           df_test[df_test.columns[0]].value_counts().index), \n",
    "                          axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_movies =  list(set(np.concatenate((df_train[df_train.columns[1]].value_counts().index, \n",
    "                           df_test[df_test.columns[1]].value_counts().index), \n",
    "                          axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMatrix(df, users, movies):\n",
    "    matrix = []\n",
    "    movies_nb = len(movies)\n",
    "    user_nb = len(users)\n",
    "    df_array = np.array(df, dtype=\"int\")\n",
    "    for i,user in enumerate(users):\n",
    "        filtered_movies = df_array[df_array[:,0] == user, 1]\n",
    "        filtered_ratings = df_array[df_array[:,0] == user, 2]\n",
    "        ratings = np.zeros(movies_nb)\n",
    "        for j in range(len(filtered_movies)):\n",
    "            ratings[filtered_movies[j] - 1] = filtered_ratings[j]\n",
    "        matrix.append(ratings)\n",
    "                      \n",
    "        sys.stdout.write(\"\\r Loading State : {} / {}\".format(i+1,user_nb))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading State : 943 / 943"
     ]
    }
   ],
   "source": [
    "matrix_train = createMatrix(df_train, _users, _movies)\n",
    "matrix_test = createMatrix(df_test, _users, _movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.FloatTensor(matrix_train)\n",
    "test = torch.FloatTensor(matrix_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([943, 1682])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SparseAutoEncoder, self).__init__()\n",
    "        # creating input layer\n",
    "        self.fully_connected_hidden_layer_1 = nn.Linear(input_dim, 20)\n",
    "        self.fully_connected_hidden_layer_2 = nn.Linear(20, 10)\n",
    "        self.fully_connected_hidden_layer_3 = nn.Linear(10, 20)\n",
    "        self.fully_connected_hidden_layer_4 = nn.Linear(20, input_dim)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.optimizer = optim.RMSprop(self.parameters(), lr=0.01, weight_decay=0.5)\n",
    "        self.loss = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.fully_connected_hidden_layer_4(\n",
    "            self.activation(self.fully_connected_hidden_layer_3(\n",
    "                self.activation(self.fully_connected_hidden_layer_2(\n",
    "                    self.activation(self.fully_connected_hidden_layer_1(X)))))))\n",
    "    \n",
    "    def train_(self, X, epoch):\n",
    "        self.X_train = X\n",
    "        for i in range(epoch):\n",
    "            print(\"Epoch => {}/{}\".format(i+1,epoch))\n",
    "            train_loss = 0\n",
    "            s = 0.\n",
    "            for j in range(self.X_train.shape[0]):\n",
    "                batch = Variable(self.X_train[j]).unsqueeze(0)\n",
    "                target = batch.clone()\n",
    "                if torch.sum(target.data > 0) > 0:\n",
    "                    output = self(batch)\n",
    "                    target.require_grad = False\n",
    "                    output[target == 0] = 0\n",
    "                    temp_loss = self.loss(output, target)\n",
    "                    \n",
    "                    mean_corrector = self.X_train.shape[1] / (float(torch.sum(target.data > 0)) + 1e-10)\n",
    "                    temp_loss.backward()\n",
    "                    train_loss += np.sqrt(temp_loss.item() * mean_corrector)\n",
    "                    s+=1.\n",
    "                    self.optimizer.step()\n",
    "            print(\"   => Loss : {}\".format((train_loss/s)))\n",
    "            \n",
    "    def test_(self, X):\n",
    "        test_loss = 0\n",
    "        s = 0.\n",
    "        sys.stdout.write(\"\\r Processing\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        for j in range(self.X_train.shape[0]):\n",
    "            batch = Variable(self.X_train[j]).unsqueeze(0)\n",
    "            target = Variable(X[j]).unsqueeze(0)\n",
    "            if torch.sum(target.data > 0) > 0:\n",
    "                output = self(batch)\n",
    "                target.require_grad = False\n",
    "                output[target == 0] = 0\n",
    "                temp_loss = self.loss(output, target)\n",
    "                    \n",
    "                mean_corrector = self.X_train.shape[1] / (float(torch.sum(target.data > 0)) + 1e-10)\n",
    "                test_loss += np.sqrt(temp_loss.item() * mean_corrector)\n",
    "                s+=1.\n",
    "        sys.stdout.write(\"\\r Test Set => Loss : {}\".format((test_loss/s)))\n",
    "        sys.stdout.flush()\n",
    "            \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = SparseAutoEncoder(train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch => 1/20\n",
      "   => Loss : 1.7715910420976406\n",
      "Epoch => 2/20\n",
      "   => Loss : 1.0966187315622766\n",
      "Epoch => 3/20\n",
      "   => Loss : 1.0534908873056288\n",
      "Epoch => 4/20\n",
      "   => Loss : 1.0380864423484002\n",
      "Epoch => 5/20\n",
      "   => Loss : 1.0311407656719527\n",
      "Epoch => 6/20\n",
      "   => Loss : 1.0265132566564796\n",
      "Epoch => 7/20\n",
      "   => Loss : 1.0239976540198936\n",
      "Epoch => 8/20\n",
      "   => Loss : 1.0220266959738937\n",
      "Epoch => 9/20\n",
      "   => Loss : 1.0209420041093658\n",
      "Epoch => 10/20\n",
      "   => Loss : 1.0196439537372004\n",
      "Epoch => 11/20\n",
      "   => Loss : 1.0189271599642897\n",
      "Epoch => 12/20\n",
      "   => Loss : 1.0183032493250952\n",
      "Epoch => 13/20\n",
      "   => Loss : 1.0178964247724989\n",
      "Epoch => 14/20\n",
      "   => Loss : 1.0173872598783607\n",
      "Epoch => 15/20\n",
      "   => Loss : 1.0172698467725836\n",
      "Epoch => 16/20\n",
      "   => Loss : 1.0166608819642282\n",
      "Epoch => 17/20\n",
      "   => Loss : 1.0168078470610282\n",
      "Epoch => 18/20\n",
      "   => Loss : 1.0165371745710432\n",
      "Epoch => 19/20\n",
      "   => Loss : 1.0163025495834048\n",
      "Epoch => 20/20\n",
      "   => Loss : 1.015942291449781\n"
     ]
    }
   ],
   "source": [
    "sae.train_(train, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Set => Loss : 1.0229144248873956"
     ]
    }
   ],
   "source": [
    "sae.test_(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
